# Implementation Plan: AI Agent Loop (Reasoning Layer)

**Branch**: `005-agent-loop`
**Date**: 2025-01-26
**Spec**: [spec.md](./spec.md)
**Input**: SPEC 005 — AI Agent Loop using OpenAI Agents SDK

---

## Summary

Implement the AI reasoning layer that interprets user messages, determines intent, invokes appropriate MCP tools (from Spec 004), and generates natural language responses. The agent uses OpenAI Agents SDK with a carefully crafted system prompt to maintain the personality defined in Constitution §2 while enforcing user isolation and statelessness.

---

## Technical Context

**Language/Version**: Python 3.11+
**Primary Dependencies**: openai-agents-sdk, FastAPI, SQLModel, Pydantic
**Storage**: Neon PostgreSQL (conversations via Spec 003)
**Testing**: pytest, pytest-asyncio
**Target Platform**: Linux server (same as backend)
**Project Type**: Agent module integrated with Chat API
**Performance Goals**: < 4 seconds end-to-end per request
**Constraints**: Stateless, user isolation mandatory, no IDs exposed to users

---

## Constitution Check

**GATE: Must pass before implementation. All items from Constitution v2.0.0.**

| Principle | Requirement | Plan Compliance |
|-----------|-------------|-----------------|
| §3.1 User Isolation | All queries filter by user_id | ✅ Agent passes user_id to every MCP tool call |
| §3.2 Stateless Server | No in-memory state | ✅ Fresh context per request from DB |
| §3.3 No Silent Failures | Friendly error messages | ✅ Error handler converts all errors to friendly messages |
| §3.4 Auth Boundary | Verify user_id from JWT | ✅ Chat API validates JWT before calling agent |
| §3.5 Natural Language | No IDs in chat | ✅ Agent matches tasks by title, never exposes IDs |
| §2 Personality | Kind, reliable, slightly warm | ✅ System prompt enforces tone |
| §7 Failure Modes | Max iterations, timeout | ✅ Agent limited to 10 iterations, 30s timeout |

**Result**: ✅ All gates pass

---

## Project Structure

### Documentation (this feature)

```
specs/005-agent-loop/
├── spec.md              # Feature specification
├── plan.md              # This file
├── research.md          # Technical decisions
├── contracts/           # Agent contracts
│   └── agent-interface.md
├── checklists/
│   └── requirements.md  # Quality validation
└── tasks.md             # Implementation tasks (generated by /sp.tasks)
```

### Source Code

```
backend/
├── agent/
│   ├── __init__.py           # Module exports
│   ├── runner.py             # AgentRunner class - main orchestrator
│   ├── context.py            # AgentContext - per-request context
│   ├── prompts/
│   │   ├── __init__.py
│   │   └── system.py         # System prompt for TodoAssistant
│   ├── tools/
│   │   ├── __init__.py
│   │   └── registry.py       # Tool definitions for OpenAI Agents SDK
│   ├── handlers/
│   │   ├── __init__.py
│   │   ├── intent.py         # Intent classification helpers (optional)
│   │   ├── language.py       # Language detection and template selection
│   │   └── response.py       # Response formatting utilities
│   ├── templates/
│   │   ├── __init__.py
│   │   └── confirmations.py  # Multi-language confirmation templates
│   └── errors.py             # Error mapping to friendly messages
├── tests/
│   └── agent/
│       ├── __init__.py
│       ├── conftest.py       # Agent test fixtures
│       ├── test_runner.py    # AgentRunner tests
│       ├── test_intent.py    # Intent recognition tests
│       ├── test_response.py  # Response formatting tests
│       ├── test_language.py  # Language detection tests
│       ├── test_errors.py    # Error handling tests
│       └── test_integration.py  # End-to-end agent tests
```

---

## Implementation Steps

### Phase 1: Foundation (Steps 1-4)

#### Step 1: Create Agent Module Structure

**Responsibility**: Set up the directory structure for agent components

**Details**:
- Create `backend/agent/` directory with `__init__.py`
- Create `backend/agent/prompts/` directory
- Create `backend/agent/tools/` directory
- Create `backend/agent/handlers/` directory
- Create `backend/tests/agent/` directory

**Constitution Alignment**: §3.2 (organized, stateless module)

---

#### Step 2: Create AgentContext Class

**Responsibility**: Define per-request context container

**Details**:
- File: `backend/agent/context.py`
- Class: `AgentContext`
- Attributes:
  - `user_id: str` - Authenticated user identifier
  - `conversation_id: str` - Current conversation UUID
  - `message_history: List[Message]` - Previous messages in conversation
- Methods:
  - `@classmethod from_request(...)` - Factory from Chat API request
- No mutable state - immutable context per request

**Constitution Alignment**: §3.2 (stateless), §3.1 (user_id for isolation)

---

#### Step 3: Create System Prompt

**Responsibility**: Define the TodoAssistant personality and behavior

**Details**:
- File: `backend/agent/prompts/system.py`
- Content: System prompt defining:
  - Identity: Kind, helpful task management assistant
  - Capabilities: Add, list, complete, update, delete tasks
  - Behavior: Confirm operations, ask for clarification, no IDs
  - Constraints: No technical jargon, friendly responses
  - Response format: Concise, emoji sparingly
- Keep prompt under 500 tokens (per Constitution §5.2)

**Constitution Alignment**: §2 (personality), §3.5 (no IDs), §10 (language style)

---

#### Step 4: Create Tool Registry

**Responsibility**: Define tools for OpenAI Agents SDK integration

**Details**:
- File: `backend/agent/tools/registry.py`
- Convert MCP tool definitions to OpenAI function format
- Tools:
  - `add_task` - Create new task
  - `list_tasks` - Get user's tasks
  - `complete_task` - Mark task as done
  - `delete_task` - Remove task
  - `update_task` - Modify task attributes
- Each tool definition includes:
  - Name, description, parameters schema
  - Maps to corresponding MCP tool function

**Integration Point**: Uses `backend/mcp/server.py` TOOL_DEFINITIONS

---

### Phase 2: Agent Core (Steps 5-8)

#### Step 5: Create Error Handler

**Responsibility**: Map technical errors to user-friendly messages

**Details**:
- File: `backend/agent/errors.py`
- Error mappings:
  - `not_found` → "I couldn't find a task about 'X' in your list."
  - `validation_error` → "Could you provide more details?"
  - `database_error` → "I'm having trouble right now. Please try again."
  - `timeout` → "That took longer than expected. Let's try again."
- Never expose: error codes, stack traces, technical details

**Constitution Alignment**: §3.3 (no silent failures, friendly messages)

---

#### Step 6: Create Response Formatter

**Responsibility**: Convert tool results to natural language

**Details**:
- File: `backend/agent/handlers/response.py`
- Functions:
  - `format_task_created(task_data, lang)` → Template-based confirmation
  - `format_task_list(tasks_data, lang)` → Formatted list with checkboxes
  - `format_task_completed(task_data, lang)` → Template-based confirmation
  - `format_task_deleted(task_data, lang)` → Template-based confirmation
  - `format_task_updated(task_data, lang)` → Template-based confirmation
- Uses language templates from Step 6a
- Follows Constitution §10 response examples

**Constitution Alignment**: §10 (personality), §3.5 (no IDs in output)

---

#### Step 6a: Create Language Detection and Templates

**Responsibility**: Detect user language and provide multi-language response templates

**Details**:
- File: `backend/agent/handlers/language.py`
- Functions:
  - `detect_language(message: str) -> str` - Returns "en", "ur", or "roman_ur"
  - Detection rules:
    - If message contains Urdu script characters → "ur"
    - If message contains Roman Urdu keywords → "roman_ur"
    - Otherwise → "en" (default)
- File: `backend/agent/templates/confirmations.py`
- Templates for each operation in 3 languages:
  - `TASK_CREATED_TEMPLATES` - add_task confirmations
  - `TASK_LISTED_TEMPLATES` - list_tasks headers
  - `TASK_COMPLETED_TEMPLATES` - complete_task confirmations
  - `TASK_DELETED_TEMPLATES` - delete_task confirmations
  - `TASK_UPDATED_TEMPLATES` - update_task confirmations
  - `TASK_NOT_FOUND_TEMPLATES` - error messages
  - `AMBIGUOUS_REQUEST_TEMPLATES` - clarification prompts

**Constitution Alignment**: FR-050 to FR-055 (language mirroring)

---

#### Step 7: Create AgentRunner Class

**Responsibility**: Main orchestrator for agent execution

**Details**:
- File: `backend/agent/runner.py`
- Class: `AgentRunner`
- Constructor:
  - `__init__(session_factory, mcp_server)` - Inject dependencies
- Methods:
  - `async run(context: AgentContext, message: str) -> AgentResult`
    1. Build agent with system prompt and tools
    2. Construct message history for context
    3. Execute agent with user message
    4. Handle tool calls via MCP server
    5. Return formatted response
- Guardrails:
  - Max 10 tool calls per request
  - 30 second timeout
  - Error handling with friendly messages

**Constitution Alignment**: §3.2 (stateless), §7 (guardrails)

---

#### Step 8: Implement Tool Execution Bridge

**Responsibility**: Connect OpenAI Agents SDK tool calls to MCP tools

**Details**:
- In `backend/agent/runner.py`
- Tool execution flow:
  1. Agent decides to call a tool
  2. Runner intercepts tool call
  3. Injects `user_id` from context into parameters
  4. Calls `mcp_server.call(tool_name, params, user_id_int)`
  5. Returns ToolResponse to agent
- User isolation enforced at this bridge point

**Constitution Alignment**: §3.1 (user_id injection), §3.4 (auth boundary)

---

### Phase 3: Intent Handling (Steps 9-12)

#### Step 9: Implement Task Matching Logic

**Responsibility**: Match user task descriptions to actual tasks

**Details**:
- File: `backend/agent/handlers/intent.py`
- Pattern: Agent calls `list_tasks`, then identifies target task
- Matching strategy:
  1. Exact title match
  2. Substring match (case-insensitive)
  3. LLM semantic matching via agent reasoning
- When ambiguous: Return options for user to choose

**Constitution Alignment**: §3.5 (no IDs from user), §2 (clarification)

---

#### Step 10: Implement Confirmation Flow

**Responsibility**: Require confirmation for destructive operations

**Details**:
- In agent system prompt + response handler
- Destructive operations:
  - Delete task: "Do you really want to delete 'X'? Reply 'yes delete' to confirm."
  - Bulk operations: "That's a big action. Confirm with 'yes all done'."
- Agent stores pending confirmation in response
- Next message checks for confirmation phrase

**Constitution Alignment**: §2 (confirm dangerous actions), §10 (examples)

---

#### Step 11: Implement General Conversation Handler

**Responsibility**: Handle non-task messages gracefully

**Details**:
- Via system prompt behavior
- Categories:
  - Greetings: "Hi! I'm here to help with your tasks. What would you like to do?"
  - Thanks: "You're welcome! Let me know if you need anything else."
  - Help: Explain capabilities (task management)
  - Off-topic: Gently redirect to tasks
- No tool calls for general conversation

**Constitution Alignment**: §2 (warm personality), User Story 6

---

#### Step 12: Create Module Exports

**Responsibility**: Clean public interface for agent module

**Details**:
- File: `backend/agent/__init__.py`
- Exports:
  - `AgentRunner` - Main entry point
  - `AgentContext` - Request context
  - `AgentResult` - Response container
- Integration: Chat API imports and uses these

**Integration Point**: Spec 003 Chat API will import AgentRunner

---

### Phase 4: Testing (Steps 13-18)

#### Step 13: Create Agent Test Fixtures

**Responsibility**: Shared test setup for agent tests

**Details**:
- File: `backend/tests/agent/conftest.py`
- Fixtures:
  - Mock MCP server with predictable responses
  - Mock OpenAI API responses
  - Sample AgentContext instances
  - Test message histories

---

#### Step 14: Test AgentRunner Core

**Responsibility**: Verify runner behavior

**Details**:
- File: `backend/tests/agent/test_runner.py`
- Tests:
  - Runner initializes correctly
  - Runner calls appropriate tool for intent
  - Runner respects max iterations limit
  - Runner respects timeout
  - Runner returns friendly error on failure

---

#### Step 15: Test Intent Recognition

**Responsibility**: Verify agent recognizes user intents

**Details**:
- File: `backend/tests/agent/test_intent.py`
- Tests:
  - "Add task buy milk" → add_task called
  - "Show my tasks" → list_tasks called
  - "I finished the milk task" → complete_task called
  - "Delete the grocery task" → delete_task called
  - "Change priority to high" → update_task called
  - "Hello" → No tool called

---

#### Step 16: Test Response Formatting

**Responsibility**: Verify response format quality

**Details**:
- File: `backend/tests/agent/test_response.py`
- Tests:
  - Task list formatted with checkboxes
  - Confirmations are concise and friendly
  - No task IDs appear in responses
  - Errors are user-friendly

---

#### Step 17: Test Error Handling

**Responsibility**: Verify error mapping

**Details**:
- File: `backend/tests/agent/test_errors.py`
- Tests:
  - not_found error → friendly "couldn't find" message
  - validation_error → friendly "provide more details" message
  - database_error → friendly "try again" message
  - No technical details in any error response

---

#### Step 18: Test User Isolation

**Responsibility**: Verify user_id is always passed

**Details**:
- File: `backend/tests/agent/test_integration.py`
- Tests:
  - Every tool call includes user_id
  - User A cannot access User B's tasks via agent
  - Agent context correctly propagates user_id
  - Tool responses filtered by user_id

---

### Phase 5: Integration (Steps 19-20)

#### Step 19: Create Agent Interface Contract

**Responsibility**: Document the public interface for Chat API

**Details**:
- File: `specs/005-agent-loop/contracts/agent-interface.md`
- Document:
  - AgentRunner.run() signature
  - AgentContext structure
  - AgentResult structure
  - Error response format
  - Integration example code

**Integration Point**: Spec 003 Chat API uses this contract

---

#### Step 20: Final Validation

**Responsibility**: End-to-end verification

**Details**:
- Run all agent tests
- Verify user isolation with multiple users
- Verify stateless behavior (no side effects between calls)
- Verify response format matches Constitution §10
- Verify all user stories pass acceptance scenarios
- Document any deviations from spec

---

## Dependencies & Execution Order

```
Step 1 (Structure)          ──→ Step 2 (AgentContext)
                                        │
                                        ▼
                                Step 3 (System Prompt)
                                        │
                                        ▼
                                Step 4 (Tool Registry)
                                        │
                                        ▼
                            ┌───────────┴───────────┐
                            ▼                       ▼
                    Step 5 (Errors)        Step 6 (Response)
                            │                       │
                            └───────────┬───────────┘
                                        ▼
                                Step 7 (AgentRunner)
                                        │
                                        ▼
                                Step 8 (Tool Bridge)
                                        │
                    ┌───────────────────┼───────────────────┐
                    ▼                   ▼                   ▼
        Step 9 (Task Match)  Step 10 (Confirm)  Step 11 (General)
                    │                   │                   │
                    └───────────────────┼───────────────────┘
                                        ▼
                                Step 12 (Exports)
                                        │
                                        ▼
                            Step 13 (Test Fixtures)
                                        │
            ┌───────────────────────────┼───────────────────────────┐
            ▼                           ▼                           ▼
Step 14 (Runner Test)    Step 15 (Intent Test)      Step 16 (Response Test)
                                                                    │
                                                                    ▼
                                                    Step 17 (Error Test)
                                                                    │
                                                                    ▼
                                                    Step 18 (Isolation Test)
                                                                    │
                                                                    ▼
                                                    Step 19 (Contract Doc)
                                                                    │
                                                                    ▼
                                                    Step 20 (Validation)
```

**Parallel Opportunities**:
- Steps 5, 6 can run in parallel (after Step 4)
- Steps 9, 10, 11 can run in parallel (after Step 8)
- Steps 14, 15, 16 can run in parallel (after Step 13)

---

## Integration Points

### Upstream Dependencies (This Spec Consumes)

| Spec | What We Use | Interface |
|------|-------------|-----------|
| 003 - Chat API | Message delivery | `POST /api/{user_id}/chat` |
| 003 - Persistence | Conversation history | Messages from DB |
| 004 - MCP Tools | Task operations | `MCPToolServer.call()` |
| Better Auth | User identity | JWT with user_id |

### Downstream Consumers (Later Specs Use This)

| Consumer | What They Use | Interface |
|----------|---------------|-----------|
| 003 - Chat API | Agent execution | `AgentRunner.run()` |
| Frontend | Chat responses | Via Chat API |

---

## Statelessness Guarantees

1. **Fresh context per request**: AgentContext created from request data
2. **No module-level state**: No globals storing user data
3. **History from DB**: Conversation history fetched fresh each request
4. **Idempotent agent**: Same input + history → same output
5. **No task caching**: Every tool call queries database

---

## Guardrails Implementation

| Protection | Limit | Implementation |
|------------|-------|----------------|
| Max tool calls | 10 per request | Counter in AgentRunner |
| Request timeout | 30 seconds | async timeout wrapper |
| Response length | ~500 chars typical | System prompt guidance |
| User isolation | Mandatory | user_id in every tool call |
| Confirmation | Delete operations | Response includes confirmation prompt |

---

## Callouts

⚠️ **MCP Tools Are Trust Boundary**: Agent trusts MCP tools to enforce user isolation. Tools MUST filter by user_id (verified in Spec 004).

⚠️ **OpenAI API Key Required**: Agent requires `OPENAI_API_KEY` environment variable for OpenAI Agents SDK.

⚠️ **Model Selection**: Using `gpt-4o-mini` for cost-effectiveness. Can upgrade to `gpt-4o` if reasoning quality needs improvement.

⚠️ **Async Execution**: AgentRunner.run() is async. Chat API must await properly.

⚠️ **Chat API Integration**: This plan creates the agent module. Spec 003 Chat API must be updated to call AgentRunner.

---

## Ready for Tasks

This plan is ready for `/sp.tasks` to generate implementable task list.
